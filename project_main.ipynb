{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Networks (RNNs):**"
      ],
      "metadata": {
        "id": "HE_eBzgZu4ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries"
      ],
      "metadata": {
        "id": "ptdyIwbuvUql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOG_af2F3EKu"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We are using the imbd dataset available in the tensorflow library.**\n",
        "\n",
        "IMDB Movie Reviews dataset. This dataset is commonly used for sentiment analysis, where the goal is to classify movie reviews as either positive or negative"
      ],
      "metadata": {
        "id": "au-CtsDbvaRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Load the IMDB dataset with the top 10,000 most frequent words\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IM4PWGTkQws",
        "outputId": "8a66959e-f4d9-4f87-98e4-9424b58cf768"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad sequences to the same length (e.g., 200 words)\n",
        "train_data = pad_sequences(train_data, maxlen=200)\n",
        "test_data = pad_sequences(test_data, maxlen=200)\n"
      ],
      "metadata": {
        "id": "fgf91Ucmkl29"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Using a LSTM model, which is one of the variants of RNN**"
      ],
      "metadata": {
        "id": "_nvpgzXgvzNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model0 = Sequential()\n",
        "model0.add(Embedding(10000, 32))  # Embedding layer for word representations\n",
        "model0.add(LSTM(32))  # LSTM layer\n",
        "model0.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model0.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "m4WE_b2xkr0L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0.fit(train_data, train_labels, epochs=50, batch_size=128, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "2raSlgE0kw6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy, precision, recall and confusion matrix of Model 0**"
      ],
      "metadata": {
        "id": "DeW7OHeRxVaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions0 = model0.predict(test_data)\n",
        "predicted_labels0 = (predictions0 > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy0 = accuracy_score(test_labels, predicted_labels0)\n",
        "precision0 = precision_score(test_labels, predicted_labels0)\n",
        "recall0 = recall_score(test_labels, predicted_labels0)\n",
        "conf_matrix0 = confusion_matrix(test_labels, predicted_labels0)\n",
        "\n",
        "print(\"Accuracy: {:.2%}\".format(accuracy0))\n",
        "print(\"Precision: {:.2%}\".format(precision0))\n",
        "print(\"Recall: {:.2%}\".format(recall0))\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wY-tMW7l7sr",
        "outputId": "1a8fcdb1-58ba-4949-8183-3e8afc8ad0ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 5ms/step\n",
            "Accuracy: 84.01%\n",
            "Precision: 83.63%\n",
            "Recall: 84.58%\n",
            "Confusion Matrix:\n",
            " [[10430  2070]\n",
            " [ 1927 10573]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Increasing the layers of the LSTM model to see how it affects the accuracy, precision and recall**"
      ],
      "metadata": {
        "id": "zb9CQRvQxtAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(10000, 32, input_length=200))  # Embedding layer for word representations\n",
        "model1.add(LSTM(64, return_sequences=True))  # First LSTM layer with return_sequences=True to stack LSTM layers\n",
        "model1.add(LSTM(32))  # Second LSTM layer\n",
        "model1.add(Dense(32, activation='relu'))  # Dense layer with ReLU activation\n",
        "model1.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "Ggpw9jfax6IZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(train_data, train_labels, epochs=50, batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "id": "OcEunu-0yZcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy, precision, recall and confusion matrix of Model 1**"
      ],
      "metadata": {
        "id": "5zSsz8Kxykzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions1 = model1.predict(test_data)\n",
        "predicted_labels1 = (predictions1 > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy1 = accuracy_score(test_labels, predicted_labels1)\n",
        "precision1 = precision_score(test_labels, predicted_labels1)\n",
        "recall1 = recall_score(test_labels, predicted_labels1)\n",
        "conf_matrix1 = confusion_matrix(test_labels, predicted_labels1)\n",
        "\n",
        "print(\"Accuracy: {:.2%}\".format(accuracy1))\n",
        "print(\"Precision: {:.2%}\".format(precision1))\n",
        "print(\"Recall: {:.2%}\".format(recall1))\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Ge04P3yqbf",
        "outputId": "4eb3f601-f280-45c8-9c48-b59e923f8831"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step\n",
            "Accuracy: 84.39%\n",
            "Precision: 84.02%\n",
            "Recall: 84.93%\n",
            "Confusion Matrix:\n",
            " [[10481  2019]\n",
            " [ 1884 10616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Using a GRU model, which is another variant of RNN**"
      ],
      "metadata": {
        "id": "-WjJH7WiwNLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(10000, 32))  # Embedding layer for word representations\n",
        "model2.add(GRU(32))  # GRU layer\n",
        "model2.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "XkhI0eFAnBsa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(train_data, train_labels, epochs=50, batch_size=128, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "lFt2R2SKnORE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy, precision, recall and confusion matrix of Model 2**"
      ],
      "metadata": {
        "id": "k1oqn790zCHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions2 = model2.predict(test_data)\n",
        "predicted_labels2 = (predictions2 > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy2 = accuracy_score(test_labels, predicted_labels2)\n",
        "precision2 = precision_score(test_labels, predicted_labels2)\n",
        "recall2 = recall_score(test_labels, predicted_labels2)\n",
        "conf_matrix2 = confusion_matrix(test_labels, predicted_labels2)\n",
        "\n",
        "print(\"Accuracy: {:.2%}\".format(accuracy2))\n",
        "print(\"Precision: {:.2%}\".format(precision2))\n",
        "print(\"Recall: {:.2%}\".format(recall2))\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLa60JC7oEvx",
        "outputId": "e872625c-a88c-41b4-88ee-5d34bd35ab2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 4ms/step\n",
            "Accuracy: 83.64%\n",
            "Precision: 84.26%\n",
            "Recall: 82.74%\n",
            "Confusion Matrix:\n",
            " [[10568  1932]\n",
            " [ 2158 10342]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Increasing the layers of the GRU model to see how it affects the accuracy, precision and recall.**"
      ],
      "metadata": {
        "id": "NrdyXasf0iup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(10000, 32, input_length=200))  # Embedding layer for word representations\n",
        "model3.add(GRU(64, return_sequences=True))  # First GRU layer with return_sequences=True to stack GRU layers\n",
        "model3.add(GRU(32))  # Second GRU layer\n",
        "model3.add(Dense(32, activation='relu'))  # Dense layer with ReLU activation\n",
        "model3.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "# model3.summary()\n"
      ],
      "metadata": {
        "id": "uLUio1Dc0x3Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(train_data, train_labels, epochs=50, batch_size=128, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPMY3F9v1F6R",
        "outputId": "d39a5d4c-30f9-411b-c7db-af20f749962e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 3s 19ms/step - loss: 4.2003e-04 - accuracy: 0.9999 - val_loss: 1.3172 - val_accuracy: 0.8578\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 4.2366e-04 - accuracy: 0.9999 - val_loss: 1.3470 - val_accuracy: 0.8568\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 3.8350e-04 - accuracy: 0.9999 - val_loss: 1.3657 - val_accuracy: 0.8572\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 3.6920e-04 - accuracy: 0.9999 - val_loss: 1.3656 - val_accuracy: 0.8572\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 3.6183e-04 - accuracy: 0.9999 - val_loss: 1.4036 - val_accuracy: 0.8578\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 3.3780e-04 - accuracy: 0.9999 - val_loss: 1.4333 - val_accuracy: 0.8568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78658067ab30>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy, precision, recall and confusion matrix of Model 3**"
      ],
      "metadata": {
        "id": "plxOy8Tl1PMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions3 = model3.predict(test_data)\n",
        "predicted_labels3 = (predictions3 > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy3 = accuracy_score(test_labels, predicted_labels3)\n",
        "precision3 = precision_score(test_labels, predicted_labels3)\n",
        "recall3 = recall_score(test_labels, predicted_labels3)\n",
        "conf_matrix3 = confusion_matrix(test_labels, predicted_labels3)\n",
        "\n",
        "print(\"Accuracy: {:.2%}\".format(accuracy3))\n",
        "print(\"Precision: {:.2%}\".format(precision3))\n",
        "print(\"Recall: {:.2%}\".format(recall3))\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZjy7oJ01ThR",
        "outputId": "f87f4453-2ba7-49a1-fcc4-b0790c4d0d74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 7ms/step\n",
            "Accuracy: 84.70%\n",
            "Precision: 85.00%\n",
            "Recall: 84.29%\n",
            "Confusion Matrix:\n",
            " [[10640  1860]\n",
            " [ 1964 10536]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}